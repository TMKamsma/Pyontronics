{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General MG Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ESN import EchoStateNetwork\n",
    "from ESN import MackeyGlassGenerator\n",
    "from ESN import GinfActivator\n",
    "\n",
    "ginf_activator = GinfActivator(V_min=-2, V_max=2, resolution=200, offset=True)\n",
    "\n",
    "def mse(test, predictions):\n",
    "    return np.mean((predictions[100:] - test[100:]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def relu(x):\n",
    "    return np.clip(x, 0, 2)\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softsign(x):\n",
    "    return x / (1 + np.abs(x))\n",
    "\n",
    "activation_functions = {\n",
    "    \"tanh\": np.tanh,\n",
    "    \"clip\": relu,\n",
    "    \"leaky_relu\": leaky_relu,\n",
    "    \"sigmoid\": sigmoid,\n",
    "    \"softsign\": softsign,\n",
    "    \"ginf\": ginf_activator.activate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    tau = np.random.randint(10, 30)\n",
    "    trial.set_user_attr(\"tau\", tau)\n",
    "\n",
    "    mg_series = MackeyGlassGenerator(tau=tau, n=10000, n_samples=5000)\n",
    "    mg_series = 2 * (mg_series - mg_series.min()) / (mg_series.max() - mg_series.min()) - 1\n",
    "\n",
    "    inputs = mg_series[:-1].reshape(-1, 1)\n",
    "    targets = mg_series[1:].reshape(-1, 1)\n",
    "\n",
    "    train_len = 4000\n",
    "    test_len = 1000\n",
    "    train_inputs = inputs[:train_len]\n",
    "    train_targets = targets[:train_len]\n",
    "    test_inputs = inputs[train_len : train_len + test_len]\n",
    "    test_targets = targets[train_len : train_len + test_len]\n",
    "\n",
    "    reservoir_size = trial.suggest_int(\"reservoir_size\", 1, 400, log=True)\n",
    "    leaking_rate = trial.suggest_float(\"leaking_rate\", 0.01, 1.0)\n",
    "    step_size = trial.suggest_float(\"step_size\", 0.0001, 1, log=True)\n",
    "    time_scale = trial.suggest_float(\"time_scale\", 0.1, 5.0)\n",
    "    spectral_radius = trial.suggest_float(\"spectral_radius\", 0.1, 1)\n",
    "    sparsity = trial.suggest_float(\"sparsity\", 0.01, 0.99)\n",
    "    input_scaling = trial.suggest_float(\"input_scaling\", 0.1, 10.0, log=True)\n",
    "    regularization = trial.suggest_float(\"regularization\", 1e-6, 1e-2, log=True)\n",
    "\n",
    "    activation_name = trial.suggest_categorical(\"activation\", list(activation_functions.keys()))\n",
    "    trial.set_user_attr(\"Activation name\", activation_name)\n",
    "    activation_func = activation_functions[activation_name]\n",
    "\n",
    "    # Enforce the constraint before constructing the ESN\n",
    "    if leaking_rate * (step_size / time_scale) > 1:\n",
    "        raise optuna.exceptions.TrialPruned(\"Leaking rate * step_size/time_scale > 1\")\n",
    "\n",
    "    esn = EchoStateNetwork(\n",
    "        input_dim=1,\n",
    "        reservoir_size=reservoir_size,\n",
    "        output_dim=1,\n",
    "        leaking_rate=leaking_rate,\n",
    "        step_size=step_size,\n",
    "        time_scale=time_scale,\n",
    "        spectral_radius=spectral_radius,\n",
    "        sparsity=sparsity,\n",
    "        input_scaling=input_scaling,\n",
    "        regularization=regularization,\n",
    "        activation=activation_func,\n",
    "        guarantee_ESP=True,\n",
    "    )\n",
    "    esn.fit(train_inputs, train_targets, washout=200)\n",
    "\n",
    "    predictions = esn.predict(test_inputs)\n",
    "    loss = mse(test_targets, predictions)\n",
    "    return min(loss, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    study_name=\"ESN optimization MG ðŸ”¥\"\n",
    "    storage=\"sqlite:///optuna_esn_MG.db\"\n",
    "\n",
    "    optuna.delete_study(study_name=study_name, storage=storage)\n",
    "except Exception:\n",
    "    print(\"No database available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=600, n_jobs=-1)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!optuna-dashboard sqlite:///optuna_esn_MG.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ventilator data Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import polars as pl\n",
    "\n",
    "from ESN import EchoStateNetwork\n",
    "from ESN import GinfActivator\n",
    "\n",
    "ginf_activator = GinfActivator(V_min=-2, V_max=2, resolution=200, offset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv(r\"data\\ventilator-pressure-prediction\\train.csv\")[:10000]\n",
    "\n",
    "data = data.to_dummies(columns=[\"R\", \"C\"])\n",
    "\n",
    "# data = data.with_columns(\n",
    "#     pl.col(\"u_in\").cum_sum().over(\"breath_id\").alias(\"u_in_cumsum\")\n",
    "# )\n",
    "\n",
    "# data = data.with_columns(\n",
    "#     pl.col(\"time_step\")\n",
    "#     .diff()\n",
    "#     .over(\"breath_id\")\n",
    "#     .fill_null(0)\n",
    "#     .map_elements(lambda x: max(x, 0), pl.Float64)\n",
    "#     .alias(\"time_delta\")\n",
    "# )\n",
    "\n",
    "# data = data.with_columns(\n",
    "#     (pl.col(\"time_delta\") * pl.col(\"u_in\")).alias(\"u_in_area\")\n",
    "# ).with_columns(pl.col(\"u_in_area\").cum_sum().over(\"breath_id\").alias(\"area_true\"))\n",
    "\n",
    "# data = data.with_columns(\n",
    "#     pl.col(\"u_in\").diff().over(\"breath_id\").fill_null(0).alias(\"u_in_diff\")\n",
    "# )\n",
    "\n",
    "split = int(len(data) * 0.8)\n",
    "\n",
    "train_x = data.drop('id','breath_id',\"pressure\")[:split].to_numpy()\n",
    "train_y = data[[\"pressure\"]][:split].to_numpy()\n",
    "test_x = data.drop('id','breath_id',\"pressure\")[split:].to_numpy()\n",
    "test_y = data[[\"pressure\"]][split:].to_numpy()\n",
    "\n",
    "data.drop('id','breath_id',\"pressure\")[:split].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    reservoir_size = trial.suggest_int(\"reservoir_size\", 1, 100, log=True)\n",
    "    leaking_rate = trial.suggest_float(\"leaking_rate\", 0.01, 1.0)\n",
    "    step_size = trial.suggest_float(\"step_size\", 0.0001, 1, log=True)\n",
    "    time_scale = trial.suggest_float(\"time_scale\", 0.1, 5.0)\n",
    "    spectral_radius = trial.suggest_float(\"spectral_radius\", 0.1, 1)\n",
    "    sparsity = trial.suggest_float(\"sparsity\", 0.01, 0.99)\n",
    "    input_scaling = trial.suggest_float(\"input_scaling\", 0.1, 10.0, log=True)\n",
    "    regularization = trial.suggest_float(\"regularization\", 1e-6, 1e-2, log=True)\n",
    "\n",
    "    if leaking_rate * (step_size / time_scale) > 1:\n",
    "        raise optuna.exceptions.TrialPruned(\"Leaking rate * step_size/time_scale > 1\")\n",
    "\n",
    "    esn = EchoStateNetwork(\n",
    "        input_dim=train_x.shape[1],\n",
    "        reservoir_size=reservoir_size,\n",
    "        output_dim=train_y.shape[1],\n",
    "        leaking_rate=leaking_rate,\n",
    "        step_size=step_size,\n",
    "        time_scale=time_scale,\n",
    "        spectral_radius=spectral_radius,\n",
    "        sparsity=sparsity,\n",
    "        input_scaling=input_scaling,\n",
    "        regularization=regularization,\n",
    "        activation=ginf_activator.activate,\n",
    "        guarantee_ESP=True,\n",
    "        progress_bar=False\n",
    "    )\n",
    "\n",
    "    esn.fit(train_x, train_y, washout=100)\n",
    "\n",
    "    predictions = esn.predict(test_x)\n",
    "    return np.mean((predictions - test_y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_name=\"ESN optimization Ventilator\"\n",
    "storage=\"sqlite:///optuna_esn_MG.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.delete_study(study_name=study_name, storage=storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=500, n_jobs=-1)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
